{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops.layers.torch import Rearrange\n",
    "import argparse\n",
    "import torch\n",
    "from dataset import make_data_loaders\n",
    "from model import MMCFormer\n",
    "\n",
    "from eval_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "parser = argparse.ArgumentParser(description='MMCFormer')\n",
    "\n",
    "parser.add_argument('--task_name',type=str, default='MMCFormer', \n",
    "                    help='task name')\n",
    "parser.add_argument('--saved_model_path', type=str, default='./results/', \n",
    "                    help='Pre-trained model path')\n",
    "parser.add_argument('--path_to_data', type=str, default='../../brats/MICCAI_BraTS_2018_Data_Training/', \n",
    "                    help='path to dataset')\n",
    "parser.add_argument('--modalities', type=str, nargs='*', default=['t1ce', 't1', 'flair', 't2'], \n",
    "                    help='List of modalities needd to be used for training and evaluating the model')\n",
    "parser.add_argument('--n_missing_modalities', type=int, default=1, \n",
    "                    help='number of modalities for the missing path. Sort [flair, t1, t1ce, t2] based on your desired modalities for the missing path')\n",
    "\n",
    "parser.add_argument('--number_classes', type=int, default=4, \n",
    "                    help='number of classes in the target dataset')\n",
    "parser.add_argument('--batch_size_tr', type=int, default=1, \n",
    "                    help='batch size for train')\n",
    "parser.add_argument('--batch_size_va', type=int, default=1, \n",
    "                    help='batch size for validation')\n",
    "parser.add_argument('--test_p', type=float, default=0.2, \n",
    "                    help='test percentage (20%)')\n",
    "parser.add_argument('--progress_p', type=float, default=0.1, \n",
    "                    help='value between 0-1 shows the number of time we need to report training progress in each epoch')\n",
    "parser.add_argument('--validation_p', type=float, default=0.1, \n",
    "                    help='validation percentage')\n",
    "parser.add_argument('--inputshape', default=[160, 192, 128], \n",
    "                    help='input shape')\n",
    "\n",
    "parser.add_argument('--missing_in_chans', type=int, default=1, \n",
    "                    help='missing modality input channels')\n",
    "parser.add_argument('--full_in_chans', type=int, default=4, \n",
    "                    help='full modality input channels')\n",
    "\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "args.modalities = ['t1ce', 't2', 't1', 'flair']\n",
    "loaders = make_data_loaders(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(inp_shape , num_classes, full_in_chans, missing_in_chans):\n",
    "    model_full    = MMCFormer(model_mode='full', img_size = inp_shape, num_classes=num_classes, in_chans=full_in_chans, \n",
    "                              head_count=1, token_mlp_mode=\"mix_skip\").cuda()\n",
    "    model_missing = MMCFormer(model_mode='missing', img_size = inp_shape, num_classes=num_classes, in_chans=missing_in_chans,\n",
    "                              head_count=1, token_mlp_mode=\"mix_skip\").cuda()\n",
    "    \n",
    "    return model_full, model_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_full, model_missing, saved_model_path):\n",
    "    print(\"Constructing model from saved file... \")\n",
    "    checkpoint = torch.load(saved_model_path)\n",
    "    model_full.load_state_dict(checkpoint[\"model_full\"])\n",
    "    model_missing.load_state_dict(checkpoint[\"model_missing\"])\n",
    "\n",
    "    return model_full, model_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model_full, model_missing = build_model(inp_shape = args.inputshape, num_classes=args.number_classes,\n",
    "                                        full_in_chans=args.full_in_chans, missing_in_chans=args.missing_in_chans)\n",
    "model_full, model_missing= load_model(model_full, model_missing, args.saved_model_path)\n",
    "model_missing.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores_miss=0\n",
    "val_loss_wt=0\n",
    "val_loss_et=0\n",
    "val_loss_ct=0\n",
    "        \n",
    "for phase in ['eval']:\n",
    "    loader = loaders[phase]\n",
    "    total = len(loader)\n",
    "    for batch_id, (batch_x, batch_y) in enumerate(loader):\n",
    "        batch_x, batch_y = batch_x.cuda(non_blocking=True), batch_y.cuda(non_blocking=True)\n",
    "\n",
    "        batch_x = Rearrange('b c h w d -> b c d h w')(batch_x)\n",
    "        batch_y = Rearrange('b c h w d -> b c d h w')(batch_y)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_missing = model_missing(batch_x[:, 0: args.n_missing_modalities])\n",
    "\n",
    "\n",
    "        val_sc_miss, val_wt_miss, val_et_miss, val_ct_miss = measure_dice_score(output_missing, batch_y, \n",
    "                                                                                thresh = [0.48, 0.42, 0.31],\n",
    "                                                                                wt_j=3, ct_j=2, et_j=None)\n",
    "\n",
    "\n",
    "        val_scores_miss += val_sc_miss\n",
    "        val_loss_wt += val_wt_miss\n",
    "        val_loss_et += val_et_miss\n",
    "        val_loss_ct += val_ct_miss\n",
    "\n",
    "        # output\n",
    "        dice_missing_1 = (val_scores_miss/(batch_id+1)) \n",
    "        dice_wt_1 = (val_loss_wt/(batch_id+1))\n",
    "        dice_et_1 = (val_loss_et/(batch_id+1))\n",
    "        dice_ct_1 = (val_loss_ct/(batch_id+1))\n",
    "\n",
    "\n",
    "    print(f'### Val DSC missing: {dice_missing_1}, WT: {dice_wt_1}, CT: {dice_ct_1}, ET: {dice_et_1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
